{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.8.17","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**Data Preprocessing and Text Generation with GPT-2**\n\n\nThis notebook offers a detailed walkthrough of data preprocessing and text generation using the GPT-2 model. It aims to empower users with the necessary skills to effectively process text data and utilize the potential of GPT-2 for creative text generation that can be later used for image generation prompts for Models like StableDiffusionXL from HuggingFace,Dalle,Midjourney and many more models from HuggingFace. The notebook covers the following key steps:\n\n1. **Data Loading:** The process begins with loading a dataset from a CSV file. The dataset contains text descriptions, and the goal is to refine and fine-tune this data for the GPT-2 model.\n\n2. **Text Cleaning:** A custom function is employed for text cleaning. This function eliminates special characters, numbers, and superfluous whitespaces, converts text to lowercase, tokenizes it, removes stopwords, and applies stemming. This meticulous cleaning process results in refined text data ready for analysis.\n\n3. **Attribute Selection:** In this step, the notebook focuses on structured data attributes. It checks the existence of specific columns in the dataset and fills missing values with zeros. Then, it scales the values using Min-Max scaling to standardize the data for further analysis.\n\n4. **Text Generation with GPT-2:** The notebook introduces the use of the GPT-2 model for text generation. It employs the Transformers library to fine-tune the GPT-2 model on a specific dataset of text prompts. This ensures that the model can generate creative and contextually relevant text based on the input prompts.\n\n5. **Training and Saving the Model:** The notebook outlines the training process, including specifying training arguments and data collation for language modeling. It also provides the steps to fine-tune the GPT-2 model and save the fine-tuned model for future use.\n\n\n**Acknowledgments:**\nWe express our gratitude to the open-source libraries and datasets used in this notebook, including Pandas, NLTK, Transformers, and the GPT-2 model Mainly HuggingFace :) So much love.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\n# Load your dataset into a DataFrame\ndf = pd.read_csv('/kaggle/input/prompt-unfiltered-dataset/dataset_final.csv', delimiter='\\t')\n","metadata":{"id":"8J9iCG650RxV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install nltk\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import nltk\nnltk.download('punkt')\n","metadata":{"id":"NTi1OsWy3C9u","outputId":"995197f8-cdb6-4dd8-8ec4-721868e89663","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import nltk\nnltk.download('stopwords')\n","metadata":{"id":"Vq-yLHI13OxS","outputId":"cb16464a-89bd-4dad-c241-a1f01e0b2801","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import re\nimport pandas as pd\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import PorterStemmer\n\n# Download the 'punkt' tokenizer data\nnltk.download('punkt')\n\n# Create a sample DataFrame\ndata = {'photo_description': [\"This is a sample photo description.\", \"Another description here!\"],\n        'ai_description': [\"AI analysis of the first photo.\", \"AI description of the second one.\"]}\ndf = pd.DataFrame(data)\n\n# Define a function to clean and preprocess text data\ndef preprocess_text(text):\n    # Remove special characters, numbers, and extra whitespaces\n    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n    text = ' '.join(text.split())\n\n    # Convert text to lowercase\n    text = text.lower()\n\n    # Tokenize the text\n    tokens = word_tokenize(text)\n\n    # Remove stopwords\n    stop_words = set(stopwords.words('english'))\n    tokens = [word for word in tokens if word not in stop_words]\n\n    # Apply stemming \n    stemmer = PorterStemmer()\n    tokens = [stemmer.stem(word) for word in tokens]\n\n  \n    cleaned_text = ' '.join(tokens)\n\n    return cleaned_text\n\n\ndf['photo_description'] = df['photo_description'].apply(preprocess_text)\ndf['ai_description'] = df['ai_description'].apply(preprocess_text)\n\n# Now, df contains the preprocessed text in the specified columns\nprint(df)\n","metadata":{"id":"RACDlI4k2QfK","outputId":"bf18d7c3-875f-47ac-a24f-42cc4a4df29b","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(df.columns)","metadata":{"id":"bgMReaTJ5gUP","outputId":"9c714925-c774-4bf9-c9d5-86b81c01881c","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\n\n# Load your dataset into a DataFrame\ndf = pd.read_csv('/kaggle/input/prompt-unfiltered-dataset/dataset_final.csv', delimiter='\\t')\n\n# Check the column names in the DataFrame\nprint(df.columns)\n\n# Define the column names based on the provided structure\nstructured_columns = ['photo_width', 'photo_height', 'exif_iso', 'exif_aperture_value', 'exif_focal_length', 'exif_exposure_time', 'stats_views', 'stats_downloads', 'ai_primary_landmark_latitude', 'ai_primary_landmark_longitude', 'ai_primary_landmark_confidence', 'ai_service_1_confidence', 'ai_service_2_confidence', 'red', 'green', 'blue']\n\n# Check if 'photo_width' exists in the column names\nif 'photo_width' not in df.columns:\n    print(\"Column 'photo_width' not found in the DataFrame.\")\nelse:\n    \n    for column in structured_columns:\n        df[column].fillna(0, inplace=True)\n\n    \n    scaler = MinMaxScaler()\n\n    \n    df[structured_columns] = scaler.fit_transform(df[structured_columns])\n\n   ","metadata":{"id":"DEqH-i_c2RLK","outputId":"a5949d0b-955d-4a5e-9063-9cf45361a6c6","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save the preprocessed DataFrame to a new CSV file\ndf.to_csv('/kaggle/working/preprocessed_dataset_final.csv', index=False)\n","metadata":{"id":"-KnlC7GD8KVg","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install transformers\n\n","metadata":{"id":"pRBhu7h_96Nm","outputId":"526fccda-58d9-48d7-9c16-da43cbc0fff4","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Use a pipeline as a high-level helper\nfrom transformers import pipeline\n\npipe = pipeline(\"text-generation\", model=\"gpt2\")","metadata":{"id":"LiFTvXj1-ny0","outputId":"1c361fb7-73bb-4511-92d3-7f764a0a428a","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load model directly\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\n\ntokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\nmodel = AutoModelForCausalLM.from_pretrained(\"gpt2\")","metadata":{"id":"PRdKVV4T-609","outputId":"fb03f4d6-140f-499d-9f16-f797ef070a43","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\n# Load your dataset into a DataFrame with the first row as headers\ndf = pd.read_csv('/kaggle/input/prompt-unfiltered-dataset/dataset_final.csv', delimiter='\\t', header=0)\n\n# Now, when you run df.head(), the first row will be treated as column headers\nprint(df.head())\n","metadata":{"id":"-OH9j5H1KuEQ","outputId":"723babbf-05e1-4288-ebef-644cd4bfa93b","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\n# Define the column names as a list of strings \ncolumn_names = [\n    'photo_id', 'photo_image_url', 'photo_width', 'photo_height', 'photo_aspect_ratio',\n    'photo_description', 'exif_camera_make', 'exif_camera_model', 'exif_iso',\n    'exif_aperture_value', 'exif_focal_length', 'exif_exposure_time', 'stats_views',\n    'stats_downloads', 'ai_description', 'ai_primary_landmark_name',\n    'ai_primary_landmark_latitude', 'ai_primary_landmark_longitude',\n    'ai_primary_landmark_confidence', 'blur_hash', 'keyword_x',\n    'ai_service_1_confidence', 'ai_service_2_confidence', 'conversion_country',\n    'keyword_y', 'hex', 'red', 'green', 'blue', 'keyword', 'ai_coverage',\n    'ai_score', 'collection_title'\n]\n\n# Load your dataset into a DataFrame with the specified column names\ndf = pd.read_csv('/kaggle/input/prompt-unfiltered-dataset/dataset_final.csv', delimiter='\\t', names=column_names)\n\n\nprint(df.columns)\n","metadata":{"id":"vS1Qy9inG9q6","outputId":"f1f8e5f3-f618-4ec2-8d72-2bf53691b116","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['image_prompt'] = (\n    'A captivating photograph (' + df['photo_id'].astype(str) + ') with dimensions ' +\n    df['photo_width'].astype(str) + 'x' + df['photo_height'].astype(str) + ', '\n)\n\ndf['image_prompt'] += (\n    'captured with a ' + df['exif_camera_make'].astype(str) + ' ' +\n    df['exif_camera_model'].astype(str) + ' camera. '\n)\n\ndf['image_prompt'] += (\n    'Shot at ' + df['ai_primary_landmark_name'].astype(str) + ' in ' +\n    df['conversion_country'].astype(str) + ', this photo ' +\n    'received ' + df['stats_views'].astype(str) + ' views and ' +\n    df['stats_downloads'].astype(str) + ' downloads. '\n)\n\ndf['image_prompt'] += (\n    'The image is associated with the collection \"' +\n    df['collection_title'].astype(str) + '\". '\n)\n\ndf['image_prompt'] += (\n    'AI analysis detected ' + df['ai_description'].astype(str) + ' with a ' +\n    'confidence score of ' + df['ai_score'].astype(str) + '. '\n)\n\ndf['image_prompt'] += (\n    'The primary landmark is located at (' +\n    df['ai_primary_landmark_latitude'].astype(str) + ', ' +\n    df['ai_primary_landmark_longitude'].astype(str) + ') with a ' +\n    'landmark confidence of ' + df['ai_primary_landmark_confidence'].astype(str) + '. '\n)\n\ndf['image_prompt'] += (\n    'The dominant colors in the image are R=' + df['red'].astype(str) +\n    ', G=' + df['green'].astype(str) + ', B=' + df['blue'].astype(str) + '. '\n)\n\ndf['image_prompt'] += (\n    'The image is labeled with keywords: ' + df['keyword_x'].astype(str) +\n    ', ' + df['keyword_y'].astype(str) + '. '\n)\n\ndf['image_prompt'] += (\n    'Additional information: ' + df['ai_coverage'].astype(str) +\n    ' coverage, ' + df['ai_service_1_confidence'].astype(str) +\n    ' service 1 confidence, ' + df['ai_service_2_confidence'].astype(str) +\n    ' service 2 confidence. '\n)\n\ndf['image_prompt'] += (\n    'The photo has a unique blur hash: ' + df['blur_hash'].astype(str) + '. '\n)\n\ndf['image_prompt'] += (\n    'The image showcases vivid colors with R=' + df['red'].astype(str) +\n    ', G=' + df['green'].astype(str) + ', B=' + df['blue'].astype(str) + '. '\n)\n\ndf['image_prompt'] += (\n    'It was converted in ' + df['conversion_country'].astype(str) +\n    ' and is associated with the keyword ' + df['keyword'].astype(str) + '. '\n)\n\ndf['image_prompt'] += (\n    'The photo is available at ' + df['photo_image_url'].astype(str) + '. '\n)\n\ndf['image_prompt'] += (\n    'It has an aspect ratio of ' + df['photo_aspect_ratio'].astype(str) +\n    ' and dimensions ' + df['photo_width'].astype(str) + 'x' + df['photo_height'].astype(str) + '. '\n)\n\ndf['image_prompt'] += (\n    'Taken with ' + df['exif_iso'].astype(str) + ' ISO, an aperture value of ' +\n    df['exif_aperture_value'].astype(str) + ', and a focal length of ' + df['exif_focal_length'].astype(str) + 'mm. '\n)\n\ndf['image_prompt'] += (\n    'The exposure time was ' + df['exif_exposure_time'].astype(str) + ' seconds. '\n)\n\ndf['image_prompt'] += (\n    'A piece of art captured with a ' + df['exif_camera_make'].astype(str) + ' ' +\n    df['exif_camera_model'].astype(str) + ' camera. '\n)\n\ndf['image_prompt'] += (\n    'This image was taken with an ISO setting of ' + df['exif_iso'].astype(str) + \n    ' and an aperture value of ' + df['exif_aperture_value'].astype(str) + '. '\n)\n\ndf['image_prompt'] += (\n    'The focal length was ' + df['exif_focal_length'].astype(str) + \n    ' mm, and the exposure time was ' + df['exif_exposure_time'].astype(str) + ' seconds. '\n)\n\ndf['image_prompt'] += (\n    'It has been viewed ' + df['stats_views'].astype(str) + ' times and downloaded ' + \n    df['stats_downloads'].astype(str) + ' times. '\n)\n\ndf['image_prompt'] += (\n    'The AI analysis detected ' + df['ai_description'].astype(str) + ' with a confidence score of ' + \n    df['ai_score'].astype(str) + '. '\n)\n\ndf['image_prompt'] += (\n    'The primary landmark, ' + df['ai_primary_landmark_name'].astype(str) + ', is situated at (' + \n    df['ai_primary_landmark_latitude'].astype(str) + ', ' + df['ai_primary_landmark_longitude'].astype(str) + ') '\n)\n\ndf['image_prompt'] += (\n    'with a confidence score of ' + df['ai_primary_landmark_confidence'].astype(str) + '. '\n)\n\ndf['image_prompt'] += (\n    'The dominant colors in the image are R=' + df['red'].astype(str) + ', G=' + df['green'].astype(str) + \n    ', B=' + df['blue'].astype(str) + '. '\n)\n\ndf['image_prompt'] += (\n    'This photo is part of the collection \"' + df['collection_title'].astype(str) + '\" '\n)\n\ndf['image_prompt'] += (\n    'with keywords: ' + df['keyword_x'].astype(str) + ', ' + df['keyword_y'].astype(str) + '.'\n)\n\ndf['image_prompt'] += (\n    'The image has an aspect ratio of ' + df['photo_aspect_ratio'].astype(str) + \n    ' and dimensions ' + df['photo_width'].astype(str) + 'x' + df['photo_height'].astype(str) + '. '\n)\n\ndf['image_prompt'] += (\n    'Captured using the ' + df['exif_camera_make'].astype(str) + ' ' + \n    df['exif_camera_model'].astype(str) + ' at ' + df['exif_iso'].astype(str) + ' ISO. '\n)\n\ndf['image_prompt'] += (\n    'Focal length ' + df['exif_focal_length'].astype(str) + 'mm, aperture value ' + \n    df['exif_aperture_value'].astype(str) + ', exposure time ' + df['exif_exposure_time'].astype(str) + 's. '\n)\n\ndf['image_prompt'] += (\n    'A scene that looks like it came straight out of a dream. '\n)\n\ndf['image_prompt'] += (\n    'A perfect blend of colors and elements that capture the essence of the moment. '\n)\n\ndf['image_prompt'] += (\n    'An image that tells a story with every pixel. '\n)\n\ndf['image_prompt'] += (\n    'An incredible display of creativity and vision. '\n)\n\ndf['image_prompt'] = (\n    'This remarkable photograph was captured using a ' + df['exif_camera_make'].astype(str) + \n    ' ' + df['exif_camera_model'].astype(str) + ' camera. '\n)\n\ndf['image_prompt'] += (\n    'With an ISO of ' + df['exif_iso'].astype(str) + ' and an aperture value of ' + \n    df['exif_aperture_value'].astype(str) + ', it beautifully frames the subject. '\n)\n\ndf['image_prompt'] += (\n    'The focal length of ' + df['exif_focal_length'].astype(str) + 'mm and an exposure time of ' + \n    df['exif_exposure_time'].astype(str) + ' seconds bring life to this image. '\n)\n\ndf['image_prompt'] += (\n    'This captivating image has been viewed ' + df['stats_views'].astype(str) + ' times and downloaded ' + \n    df['stats_downloads'].astype(str) + ' times, making it truly remarkable. '\n)\n\ndf['image_prompt'] += (\n    'AI analysis detected ' + df['ai_description'].astype(str) + ' with a confidence score of ' + \n    df['ai_score'].astype(str) + '. '\n)\n\ndf['image_prompt'] += (\n    'The primary landmark is ' + df['ai_primary_landmark_name'].astype(str) + ' located at (' + \n    df['ai_primary_landmark_latitude'].astype(str) + ', ' + df['ai_primary_landmark_longitude'].astype(str) + ') '\n)\n\ndf['image_prompt'] += (\n    'with a confidence score of ' + df['ai_primary_landmark_confidence'].astype(str) + '. '\n)\n\ndf['image_prompt'] += (\n    'The prominent colors in the image are R=' + df['red'].astype(str) + ', G=' + df['green'].astype(str) + \n    ', B=' + df['blue'].astype(str) + '. '\n)\n\ndf['image_prompt'] += (\n    'This breathtaking image belongs to the collection \"' + df['collection_title'].astype(str) + '\" '\n)\n\ndf['image_prompt'] += (\n    'with keywords: ' + df['keyword_x'].astype(str) + ', ' + df['keyword_y'].astype(str) + '. '\n)\n\ndf['image_prompt'] += (\n    'The image has an aspect ratio of ' + df['photo_aspect_ratio'].astype(str) + \n    ' and dimensions ' + df['photo_width'].astype(str) + 'x' + df['photo_height'].astype(str) + '. '\n)\n\ndf['image_prompt'] += (\n    'Taken using the ' + df['exif_camera_make'].astype(str) + ' ' + \n    df['exif_camera_model'].astype(str) + ' at ' + df['exif_iso'].astype(str) + ' ISO. '\n)\n\ndf['image_prompt'] += (\n    'Focal length ' + df['exif_focal_length'].astype(str) + 'mm, aperture value ' + \n    df['exif_aperture_value'].astype(str) + ', exposure time ' + df['exif_exposure_time'].astype(str) + 's. '\n)\n\ndf['image_prompt'] += (\n    'A scene that looks like it came straight out of a dream. '\n)\n\ndf['image_prompt'] += (\n    'A perfect blend of colors and elements that capture the essence of the moment. '\n)\n\ndf['image_prompt'] += (\n    'An image that tells a story with every pixel. '\n)\n\ndf['image_prompt'] += (\n    'An incredible display of creativity and vision. '\n)\n\ndf['image_prompt'] = (\n    'A stunning photograph taken with a ' + df['exif_camera_make'].astype(str) + ' ' + \n    df['exif_camera_model'].astype(str) + ' camera, featuring '\n)\n\ndf['image_prompt'] += (\n    'an ISO of ' + df['exif_iso'].astype(str) + ', an aperture value of f/' + \n    df['exif_aperture_value'].astype(str) + ', and a focal length of ' + df['exif_focal_length'].astype(str) + 'mm. '\n)\n\ndf['image_prompt'] += (\n    'The exposure time was ' + df['exif_exposure_time'].astype(str) + ' seconds. '\n)\n\ndf['image_prompt'] += (\n    'With ' + df['stats_views'].astype(str) + ' views and ' + df['stats_downloads'].astype(str) + ' downloads, this image has garnered much attention. '\n)\n\ndf['image_prompt'] += (\n    'It was taken at (' + df['ai_primary_landmark_latitude'].astype(str) + ', ' + \n    df['ai_primary_landmark_longitude'].astype(str) + ') with ' + df['ai_primary_landmark_confidence'].astype(str) + ' landmark confidence. '\n)\n\ndf['image_prompt'] += (\n    'The image showcases dominant colors - R=' + df['red'].astype(str) + \n    ', G=' + df['green'].astype(str) + ', B=' + df['blue'].astype(str) + '. '\n)\n\ndf['image_prompt'] += (\n    'This image belongs to the collection \"' + df['collection_title'].astype(str) + \n    '\" and is associated with keywords: ' + df['keyword_x'].astype(str) + ', ' + df['keyword_y'].astype(str) + '. '\n)\n\ndf['image_prompt'] += (\n    'AI analysis detected ' + df['ai_description'].astype(str) + ' with a confidence score of ' + \n    df['ai_score'].astype(str) + '. '\n)\n\ndf['image_prompt'] += (\n    'The photograph was converted in ' + df['conversion_country'].astype(str) + '. '\n)\ndf['image_prompt'] = (\n    'This extraordinary photograph (' + df['photo_id'].astype(str) + ') showcases a ' + \n    df['ai_description'].astype(str) + ' captured with a ' + df['exif_camera_make'].astype(str) + ' ' + \n    df['exif_camera_model'].astype(str) + ' camera. '\n)\n\ndf['image_prompt'] += (\n    'The image was taken at ' + df['ai_primary_landmark_name'].astype(str) + ' with ' + \n    df['ai_primary_landmark_confidence'].astype(str) + ' landmark confidence. '\n)\n\ndf['image_prompt'] += (\n    'With dimensions ' + df['photo_width'].astype(str) + 'x' + df['photo_height'].astype(str) + ' and an aspect ratio of ' + \n    df['photo_aspect_ratio'].astype(str) + ', it offers a captivating visual experience. '\n)\n\ndf['image_prompt'] += (\n    'The photograph was captured using an ISO of ' + df['exif_iso'].astype(str) + ' and an aperture value of ' + \n    df['exif_aperture_value'].astype(str) + '. '\n)\n\ndf['image_prompt'] += (\n    'With a focal length of ' + df['exif_focal_length'].astype(str) + 'mm and an exposure time of ' + \n    df['exif_exposure_time'].astype(str) + ' seconds, it captures the essence of the moment. '\n)\n\ndf['image_prompt'] += (\n    'This image has been viewed ' + df['stats_views'].astype(str) + ' times and downloaded ' + \n    df['stats_downloads'].astype(str) + ' times, demonstrating its widespread appeal. '\n)\n\ndf['image_prompt'] += (\n    'The dominant colors in the photo are R=' + df['red'].astype(str) + \n    ', G=' + df['green'].astype(str) + ', B=' + df['blue'].astype(str) + '. '\n)\n\ndf['image_prompt'] += (\n    'Part of the collection \"' + df['collection_title'].astype(str) + '\", this image is enriched with keywords: ' + \n    df['keyword_x'].astype(str) + ', ' + df['keyword_y'].astype(str) + '. '\n)\n\ndf['image_prompt'] += (\n    'AI analysis confidently identified ' + df['ai_description'].astype(str) + ' with a score of ' + \n    df['ai_score'].astype(str) + '. '\n)\n\ndf['image_prompt'] += (\n    'The image underwent conversion in ' + df['conversion_country'].astype(str) + '. '\n)\n\ndf['image_prompt'] += (\n    'An image that tells a unique story through visual elegance. '\n)\n\ndf['image_prompt'] += (\n    'This photograph combines the magic of ' + df['ai_description'].astype(str) + ' with the artistry of photography. '\n)\n\ndf['image_prompt'] = (\n    'A mesmerizing photograph captured with a ' + df['exif_camera_make'].astype(str) + ' ' + \n    df['exif_camera_model'].astype(str) + ' camera. '\n)\n\ndf['image_prompt'] += (\n    'Featuring an ISO setting of ' + df['exif_iso'].astype(str) + ' and an aperture value of ' + \n    df['exif_aperture_value'].astype(str) + ', it beautifully frames the subject. '\n)\n\ndf['image_prompt'] += (\n    'The focal length of ' + df['exif_focal_length'].astype(str) + 'mm and an exposure time of ' + \n    df['exif_exposure_time'].astype(str) + ' seconds bring life to this image. '\n)\n\ndf['image_prompt'] += (\n    'AI analysis detected ' + df['ai_description'].astype(str) + ' with a confidence score of ' + \n    df['ai_score'].astype(str) + '. '\n)\n\ndf['image_prompt'] += (\n    'The primary landmark is ' + df['ai_primary_landmark_name'].astype(str) + ' located at (' + \n    df['ai_primary_landmark_latitude'].astype(str) + ', ' + df['ai_primary_landmark_longitude'].astype(str) + ') '\n)\n\ndf['image_prompt'] += (\n    'with a confidence score of ' + df['ai_primary_landmark_confidence'].astype(str) + '. '\n)\n\ndf['image_prompt'] += (\n    'The prominent colors in the image are R=' + df['red'].astype(str) + ', G=' + df['green'].astype(str) + \n    ', B=' + df['blue'].astype(str) + '. '\n)\n\ndf['image_prompt'] += (\n    'This breathtaking image belongs to the collection \"' + df['collection_title'].astype(str) + '\" '\n)\n\ndf['image_prompt'] += (\n    'with keywords: ' + df['keyword_x'].astype(str) + ', ' + df['keyword_y'].astype(str) + '. '\n)\n\ndf['image_prompt'] += (\n    'A visual journey that tells a captivating story. '\n)\n\ndf['image_prompt'] += (\n    'An exquisite blend of creativity, colors, and artistry that captivates the viewer. '\n)\n\ndf['image_prompt'] += (\n    'A photographic masterpiece that draws you into the moment it captures. '\n)\n\ndf['image_prompt'] += (\n    'An image that inspires curiosity and imagination with every pixel. '\n)\n\ndf['image_prompt'] = (\n    'This remarkable photograph was captured using a ' + df['exif_camera_make'].astype(str) + \n    ' ' + df['exif_camera_model'].astype(str) + ' camera. '\n)\n\ndf['image_prompt'] += (\n    'With an ISO of ' + df['exif_iso'].astype(str) + ' and an aperture value of ' + \n    df['exif_aperture_value'].astype(str) + ', it beautifully frames the subject. '\n)\n\ndf['image_prompt'] += (\n    'The focal length of ' + df['exif_focal_length'].astype(str) + 'mm and an exposure time of ' + \n    df['exif_exposure_time'].astype(str) + ' seconds bring life to this image. '\n)\n\ndf['image_prompt'] += (\n    'AI analysis detected ' + df['ai_description'].astype(str) + ' with a confidence score of ' + \n    df['ai_score'].astype(str) + '. '\n)\n\ndf['image_prompt'] += (\n    'The primary landmark is ' + df['ai_primary_landmark_name'].astype(str) + ' located at (' + \n    df['ai_primary_landmark_latitude'].astype(str) + ', ' + df['ai_primary_landmark_longitude'].astype(str) + ') '\n)\n\ndf['image_prompt'] += (\n    'with a confidence score of ' + df['ai_primary_landmark_confidence'].astype(str) + '. '\n)\n\ndf['image_prompt'] += (\n    'The dominant colors in the photo are R=' + df['red'].astype(str) + ', G=' + df['green'].astype(str) + \n    ', B=' + df['blue'].astype(str) + '. '\n)\n\ndf['image_prompt'] += (\n    'This photo is part of the collection \"' + df['collection_title'].astype(str) + '\" '\n)\n\ndf['image_prompt'] += (\n    'with keywords: ' + df['keyword_x'].astype(str) + ', ' + df['keyword_y'].astype(str) + '. '\n)\n\ndf['image_prompt'] += (\n    'An image that captures the essence of the moment with every detail. '\n)\n\ndf['image_prompt'] += (\n    'A masterpiece that speaks volumes through the interplay of colors and elements. '\n)\n\ndf['image_prompt'] += (\n    'A visual story that transports the viewer to another world. '\n)\n\ndf['image_prompt'] += (\n    'An exceptional composition that sparks curiosity and emotion. '\n)\n\ndf['image_prompt'] = (\n    'This incredible photograph (' + df['photo_id'].astype(str) + ') was taken with ' + \n    df['exif_camera_make'].astype(str) + ' ' + df['exif_camera_model'].astype(str) + ' camera. '\n)\n\ndf['image_prompt'] += (\n    'With an ISO setting of ' + df['exif_iso'].astype(str) + ' and an aperture value of ' + \n    df['exif_aperture_value'].astype(str) + ', the image captures the beauty of the moment. '\n)\n\ndf['image_prompt'] += (\n    'The focal length is ' + df['exif_focal_length'].astype(str) + 'mm, and the exposure time is ' + \n    df['exif_exposure_time'].astype(str) + ' seconds. '\n)\n\ndf['image_prompt'] += (\n    'This captivating image has been viewed ' + df['stats_views'].astype(str) + ' times and downloaded ' + \n    df['stats_downloads'].astype(str) + ' times, making it a truly remarkable photo. '\n)\n\ndf['image_prompt'] += (\n    'The AI analysis identifies the subject as ' + df['ai_description'].astype(str) + ' with a confidence score of ' + \n    df['ai_score'].astype(str) + '. '\n)\n\ndf['image_prompt'] += (\n    'The primary landmark in the image is ' + df['ai_primary_landmark_name'].astype(str) + ', located at (' + \n    df['ai_primary_landmark_latitude'].astype(str) + ', ' + df['ai_primary_landmark_longitude'].astype(str) + '), '\n)\n\ndf['image_prompt'] += (\n    'with a landmark confidence of ' + df['ai_primary_landmark_confidence'].astype(str) + '. '\n)\n\ndf['image_prompt'] += (\n    'The prominent colors in this photo are R=' + df['red'].astype(str) + ', G=' + df['green'].astype(str) + \n    ', B=' + df['blue'].astype(str) + '. '\n)\n\ndf['image_prompt'] += (\n    'This captivating image is part of the collection \"' + df['collection_title'].astype(str) + '\", '\n)\n\ndf['image_prompt'] += (\n    'enriched with keywords: ' + df['keyword_x'].astype(str) + ', ' + df['keyword_y'].astype(str) + '. '\n)\n\ndf['image_prompt'] += (\n    'A visual masterpiece that speaks of creativity and artistry. '\n)\n\ndf['image_prompt'] += (\n    'An image that captures a moment in time and tells a compelling story. '\n)\n\ndf['image_prompt'] += (\n    'An exquisite blend of colors and composition that draws you in. '\n)\n\ndf['image_prompt'] += (\n    'A visual journey that sparks curiosity and emotion. '\n)\ndf['image_prompt'] = (\n    'A captivating photo taken with a ' + df['exif_camera_make'].astype(str) + ' ' +\n    df['exif_camera_model'].astype(str) + ' camera. '\n)\n\ndf['image_prompt'] += (\n    'With an ISO setting of ' + df['exif_iso'].astype(str) + ' and an aperture value of ' + \n    df['exif_aperture_value'].astype(str) + ', the image beautifully captures the moment. '\n)\n\ndf['image_prompt'] += (\n    'The focal length is ' + df['exif_focal_length'].astype(str) + 'mm, and the exposure time is ' + \n    df['exif_exposure_time'].astype(str) + ' seconds. '\n)\n\ndf['image_prompt'] += (\n    'This captivating image has been viewed ' + df['stats_views'].astype(str) + ' times and downloaded ' + \n    df['stats_downloads'].astype(str) + ' times, making it truly remarkable. '\n)\n\ndf['image_prompt'] += (\n    'AI analysis identified ' + df['ai_description'].astype(str) + ' with a confidence score of ' + \n    df['ai_score'].astype(str) + '. '\n)\n\ndf['image_prompt'] += (\n    'The primary landmark in the image is ' + df['ai_primary_landmark_name'].astype(str) + ', located at (' + \n    df['ai_primary_landmark_latitude'].astype(str) + ', ' + df['ai_primary_landmark_longitude'].astype(str) + '), '\n)\n\ndf['image_prompt'] += (\n    'with a landmark confidence of ' + df['ai_primary_landmark_confidence'].astype(str) + '. '\n)\n\ndf['image_prompt'] += (\n    'The prominent colors in this photo are R=' + df['red'].astype(str) + ', G=' + df['green'].astype(str) + \n    ', B=' + df['blue'].astype(str) + '. '\n)\n\ndf['image_prompt'] += (\n    'This captivating image is part of the collection \"' + df['collection_title'].astype(str) + '\", '\n)\n\ndf['image_prompt'] += (\n    'enriched with keywords: ' + df['keyword_x'].astype(str) + ', ' + df['keyword_y'].astype(str) + '. '\n)\n\ndf['image_prompt'] += (\n    'A visual masterpiece that speaks of creativity and artistry. '\n)\n\ndf['image_prompt'] += (\n    'An image that captures a moment in time and tells a compelling story. '\n)\n\ndf['image_prompt'] += (\n    'An exquisite blend of colors and composition that draws you in. '\n)\n\ndf['image_prompt'] += (\n    'A visual journey that sparks curiosity and emotion. '\n)\n\n# Unique additions:\ndf['image_prompt'] += (\n    'An image that showcases the world in a different light, highlighting its beauty. '\n)\n\ndf['image_prompt'] += (\n    'A photographic masterpiece that evokes a sense of wonder and curiosity. '\n)\n\ndf['image_prompt'] += (\n    \" This image is more than just pixels; it's a story waiting to be explored. \" \n)\n\ndf['image_prompt'] += (\n    'A perfect fusion of technology and art, creating a captivating visual experience. '\n)\n\ndf['image_prompt'] += (\n    'An image that invites the viewer to step into the scene and become a part of the story. '\n)\n\ndf['image_prompt'] += (\n    'This photograph captures the essence of the moment, preserving it for eternity. '\n)\n\ndf['image_prompt'] += (\n    'A visual composition that transports the viewer to another world filled with beauty and wonder. '\n)\n\n","metadata":{"id":"URroU5eY-_Sy","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Select relevant columns\ndf = df[['photo_id', 'image_prompt']]\n","metadata":{"id":"dDB5-rgxGJM3","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndf.to_csv('/kaggle/working/image_prompts.csv', index=False)\n","metadata":{"id":"_fDn0ysKGLos","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install transformers\n!pip install accelerate\n","metadata":{"id":"VfhNFHWGZNI2","outputId":"d50e2ec9-7bf4-4284-be22-055b78f4eb8f","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\ndata = pd.read_csv('/kaggle/working/image_prompts.csv')  # Load the CSV file using pandas\n","metadata":{"id":"nA8PXAamcn-K","outputId":"91183401-a515-447b-dc4a-7fb6807d9c33","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv('/kaggle/working/image_prompts.csv', encoding='utf-8')\n\n","metadata":{"id":"3_hV5tY9cr26","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install --upgrade transformers torch\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\n\n# Create a Conda environment\nos.system('conda create -n myenv python=3.8')\n\n# Activate the Conda environment\nos.system('conda activate myenv')\n\n# Install PyTorch and torchvision\nos.system('conda install pytorch=1.8.1 torchvision=0.9.1 -c pytorch')\n\n# Install Python packages\nos.system('pip install transformers pandas')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set the pad_token for the tokenizer\ntokenizer.pad_token = tokenizer.eos_token  # You can use a different token if needed\n\n# Tokenize the \"image_prompt\" column\ntokenized_datasets = data[\"image_prompt\"].apply(lambda x: tokenizer(x, padding=\"max_length\", truncation=True))\n\n","metadata":{"id":"3EJ942_OesSF","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install accelerate -U","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install transformers[torch]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install accelerate\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install transformers[torch]\n","metadata":{"execution":{"iopub.status.busy":"2023-10-11T15:46:40.843811Z","iopub.execute_input":"2023-10-11T15:46:40.844142Z","iopub.status.idle":"2023-10-11T15:46:45.415709Z","shell.execute_reply.started":"2023-10-11T15:46:40.844113Z","shell.execute_reply":"2023-10-11T15:46:45.414854Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.8/site-packages (4.34.0)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/site-packages (from transformers[torch]) (2023.10.3)\nRequirement already satisfied: requests in /usr/local/lib/python3.8/site-packages (from transformers[torch]) (2.31.0)\nRequirement already satisfied: tokenizers<0.15,>=0.14 in /usr/local/lib/python3.8/site-packages (from transformers[torch]) (0.14.1)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/site-packages (from transformers[torch]) (1.23.5)\nRequirement already satisfied: filelock in /usr/local/lib/python3.8/site-packages (from transformers[torch]) (3.12.2)\nRequirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.8/site-packages (from transformers[torch]) (0.4.0)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/site-packages (from transformers[torch]) (4.65.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.8/site-packages (from transformers[torch]) (0.17.3)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/site-packages (from transformers[torch]) (23.1)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/site-packages (from transformers[torch]) (6.0)\nRequirement already satisfied: torch!=1.12.0,>=1.10 in /usr/local/lib/python3.8/site-packages (from transformers[torch]) (2.0.0)\nRequirement already satisfied: accelerate>=0.20.3 in /usr/local/lib/python3.8/site-packages (from transformers[torch]) (0.23.0)\nRequirement already satisfied: psutil in /usr/local/lib/python3.8/site-packages (from accelerate>=0.20.3->transformers[torch]) (5.9.5)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers[torch]) (2023.9.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers[torch]) (4.7.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.8/site-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (3.1)\nRequirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.8/site-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (2.0.0)\nRequirement already satisfied: sympy in /usr/local/lib/python3.8/site-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (1.12)\nRequirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.8/site-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (11.7.99)\nRequirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.8/site-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (11.7.4.91)\nRequirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.8/site-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (11.7.101)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.8/site-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (11.7.99)\nRequirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.8/site-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (8.5.0.96)\nRequirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.8/site-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (11.4.0.1)\nRequirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.8/site-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (10.2.10.91)\nRequirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.8/site-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (2.14.3)\nRequirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.8/site-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (11.10.3.66)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.8/site-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (3.1.2)\nRequirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.8/site-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (10.9.0.58)\nRequirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.8/site-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (11.7.91)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.8/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch!=1.12.0,>=1.10->transformers[torch]) (57.5.0)\nRequirement already satisfied: wheel in /usr/local/lib/python3.8/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch!=1.12.0,>=1.10->transformers[torch]) (0.40.0)\nRequirement already satisfied: cmake in /usr/local/lib/python3.8/site-packages (from triton==2.0.0->torch!=1.12.0,>=1.10->transformers[torch]) (3.26.4)\nRequirement already satisfied: lit in /usr/local/lib/python3.8/site-packages (from triton==2.0.0->torch!=1.12.0,>=1.10->transformers[torch]) (16.0.6)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/site-packages (from requests->transformers[torch]) (3.2.0)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.8/site-packages (from requests->transformers[torch]) (1.26.16)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/site-packages (from requests->transformers[torch]) (3.4)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/site-packages (from requests->transformers[torch]) (2023.5.7)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.8/site-packages (from jinja2->torch!=1.12.0,>=1.10->transformers[torch]) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.8/site-packages (from sympy->torch!=1.12.0,>=1.10->transformers[torch]) (1.3.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import GPT2Tokenizer, GPT2LMHeadModel, TextDataset, DataCollatorForLanguageModeling, Trainer, TrainingArguments\nimport pandas as pd\n\n# Load the pre-trained GPT-2 model \nmodel_name = \"gpt2-medium\"  \ntokenizer = GPT2Tokenizer.from_pretrained(model_name)\nmodel = GPT2LMHeadModel.from_pretrained(model_name)\n\n# Add a new pad token\ntokenizer.add_special_tokens({'pad_token': '[PAD]'})\n\n# Load your image prompts dataset \ndataset_path = \"/kaggle/working/image_prompts.csv\"  # Update with your dataset path\ndata = pd.read_csv(dataset_path)  # Load the CSV file using pandas\n\n# Tokenize the \"image_prompt\" column with a smaller max_length\ntokenized_datasets = data[\"image_prompt\"].apply(lambda x: tokenizer(x, padding=\"max_length\", truncation=True, max_length=64))\n\n# Define data collator\ndata_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n\n\ntraining_args = TrainingArguments(\n    output_dir=\"./gpt2-finetuned\",  \n    overwrite_output_dir=True,\n    num_train_epochs=3,  \n    per_device_train_batch_size=2,  \n    save_steps=10_000,  \n    save_total_limit=2,  \n    evaluation_strategy=\"steps\",\n    eval_steps=10_000,  \n    learning_rate=2e-5,  \n)\n\n# Create Trainer instance\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    data_collator=data_collator,\n    train_dataset=tokenized_datasets.tolist(),  # Convert to list\n)\n\n# Fine-tune the model\ntrainer.train()\n\n# Save the fine-tuned model\ntrainer.save_model()\n","metadata":{"id":"r2pS1j-tZiwT","execution":{"iopub.status.busy":"2023-10-11T15:46:50.699397Z","iopub.execute_input":"2023-10-11T15:46:50.699771Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}